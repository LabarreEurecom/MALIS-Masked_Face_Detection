{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MASK WEAR DETECTION WITH LOGISTIC REGRESSION :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to load set of images.\n",
    "\n",
    "To begin, we will load 2 sets of 100 images (1 dataset with worn mask and 1 dataset with unworn mask)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    '''load all the images from a folder'''\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        '''\n",
    "        Python method listdir() returns a list containing the names of the \n",
    "        entries in the directory given by path. The list is in arbitrary order. \n",
    "        It does not include the special entries '.' and '..' even if they are \n",
    "        present in the directory.'''\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            img = img[:,:,::-1] # To shuffle the color channels form BGR to RGB.\n",
    "            # A REGARDER COMMENT CA MARCHE PLUS EN DETAIL \n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "#dataset_w_m = torch.from_numpy(np.array(load_images_from_folder('Worn_Mask')))\n",
    "#dataset_unw_m = torch.from_numpy(np.array(load_images_from_folder('Unworn_Mask')))\n",
    "\n",
    "dataset_w_m_array = np.array(load_images_from_folder('Worn_Mask'))\n",
    "dataset_unw_m_array = np.array(load_images_from_folder('Unworn_Mask'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Show the first element of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  3, 135, 148],\n",
       "        [  4, 136, 149],\n",
       "        [  4, 134, 148],\n",
       "        ...,\n",
       "        [  0, 115, 148],\n",
       "        [  0, 117, 150],\n",
       "        [  0, 116, 149]],\n",
       "\n",
       "       [[  0, 130, 143],\n",
       "        [  2, 134, 147],\n",
       "        [  5, 135, 149],\n",
       "        ...,\n",
       "        [  0, 116, 149],\n",
       "        [  0, 117, 150],\n",
       "        [  0, 116, 149]],\n",
       "\n",
       "       [[  0, 127, 142],\n",
       "        [  0, 131, 146],\n",
       "        [  3, 133, 149],\n",
       "        ...,\n",
       "        [  0, 116, 151],\n",
       "        [  0, 116, 149],\n",
       "        [  0, 114, 147]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 19, 150, 168],\n",
       "        [ 17, 148, 166],\n",
       "        [ 15, 146, 164],\n",
       "        ...,\n",
       "        [128, 153, 158],\n",
       "        [134, 157, 163],\n",
       "        [135, 160, 165]],\n",
       "\n",
       "       [[ 16, 149, 168],\n",
       "        [ 16, 149, 168],\n",
       "        [ 14, 147, 166],\n",
       "        ...,\n",
       "        [130, 158, 162],\n",
       "        [132, 157, 162],\n",
       "        [130, 158, 162]],\n",
       "\n",
       "       [[ 15, 148, 167],\n",
       "        [ 16, 149, 168],\n",
       "        [ 15, 148, 167],\n",
       "        ...,\n",
       "        [132, 160, 164],\n",
       "        [132, 160, 164],\n",
       "        [130, 158, 162]]], dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_w_m_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "dataset_unw_m = torch.from_numpy(dataset_unw_m_array)\n",
    "dataset_w_m = torch.from_numpy(dataset_w_m_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the type :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset_unw_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study on one element :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = dataset_unw_m[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show its type and its shape :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([1024, 1024, 3])\n"
     ]
    }
   ],
   "source": [
    "print(type(img_tensor))\n",
    "print(img_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[204,   0,   1],\n",
      "         [204,   0,   1],\n",
      "         [204,   0,   1],\n",
      "         [203,   0,   1],\n",
      "         [203,   0,   1]],\n",
      "\n",
      "        [[204,   0,   1],\n",
      "         [204,   0,   1],\n",
      "         [205,   0,   1],\n",
      "         [204,   0,   1],\n",
      "         [204,   0,   1]],\n",
      "\n",
      "        [[204,   0,   3],\n",
      "         [205,   0,   3],\n",
      "         [206,   0,   3],\n",
      "         [207,   0,   3],\n",
      "         [207,   0,   2]],\n",
      "\n",
      "        [[204,   0,   3],\n",
      "         [205,   0,   4],\n",
      "         [205,   0,   4],\n",
      "         [207,   0,   4],\n",
      "         [208,   0,   3]],\n",
      "\n",
      "        [[202,   1,   1],\n",
      "         [203,   0,   3],\n",
      "         [204,   0,   3],\n",
      "         [205,   0,   3],\n",
      "         [205,   0,   2]]], dtype=torch.uint8)\n",
      "tensor(255, dtype=torch.uint8) tensor(0, dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "print(img_tensor[10:15,10:15,:])\n",
    "print(torch.max(img_tensor), torch.min(img_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelization :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelize_worn_mask(dataset) :\n",
    "    image_label = []\n",
    "    \n",
    "    \n",
    "dataset_unw_m = torch.from_numpy(dataset_unw_m_array)\n",
    "dataset_w_m = torch.from_numpy(dataset_w_m_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation Datasets\n",
    "\n",
    "While building real world machine learning models, it is quite common to split the dataset into 3 parts:\n",
    "\n",
    "1. **Training set** - used to train the model i.e. compute the loss and adjust the weights of the model using gradient descent.\n",
    "2. **Validation set** - used to evaluate the model while training, adjust hyperparameters (learning rate etc.) and pick the best version of the model.\n",
    "3. **Test set** - used to compare different models, or different types of modeling approaches, and report the final accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
